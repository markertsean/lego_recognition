{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'applications' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4ca3a4617f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmomentum\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'applications' is not defined"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 256, 256\n",
    "train_data_dir        = \"data/train\"\n",
    "validation_data_dir   = \"data/test\"\n",
    "nb_train_samples      = 2000         # Number of samples to train before going to next epoch\n",
    "nb_validation_samples = 400          # Number of samples to validate on before next epoch\n",
    "batch_size            = 32           # Number of samples to run at once, due to memory constraints\n",
    "epochs                =  5           # Number of cycles of training\n",
    "n_labels              = 19           # Number of labels to fit\n",
    "dense_final_layer     = 512          # Final layer number of nodes\n",
    "final_dropout         = 0.5          # Dropout fraction\n",
    "learning_rate         = 1e-4\n",
    "momentum              = 0.9\n",
    "\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7fbe761fbb10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe761fbd10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe761fbdd0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fbe761fbf90>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe7621ee50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe761b8a10>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fbe761e08d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe76173e90>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe76183a50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe761a0910>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe761306d0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fbe76150590>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe761648d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe760ff810>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe7611b6d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe760ae490>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fbe760cc350>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe7606ded0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe760785d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe76099550>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7fbe760a8310>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7fbe76054590>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLayer (type)                 Output Shape              Param #   \\n=================================================================\\ninput_1 (InputLayer)         (None, 256, 256, 3)       0         \\n_________________________________________________________________\\nblock1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \\n_________________________________________________________________\\nblock1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \\n_________________________________________________________________\\nblock1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \\n_________________________________________________________________\\nblock2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \\n_________________________________________________________________\\nblock2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \\n_________________________________________________________________\\nblock2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \\n_________________________________________________________________\\nblock3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \\n_________________________________________________________________\\nblock3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \\n_________________________________________________________________\\nblock3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \\n_________________________________________________________________\\nblock3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \\n_________________________________________________________________\\nblock3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \\n_________________________________________________________________\\nblock4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \\n_________________________________________________________________\\nblock4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \\n_________________________________________________________________\\nblock4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \\n_________________________________________________________________\\nblock4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \\n_________________________________________________________________\\nblock4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \\n_________________________________________________________________\\nblock5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \\n_________________________________________________________________\\nblock5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \\n_________________________________________________________________\\nblock5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \\n_________________________________________________________________\\nblock5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \\n_________________________________________________________________\\nblock5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \\n=================================================================\\nTotal params: 20,024,384.0\\nTrainable params: 20,024,384.0\\nNon-trainable params: 0.0\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
    "_________________________________________________________________\n",
    "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
    "_________________________________________________________________\n",
    "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
    "_________________________________________________________________\n",
    "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
    "_________________________________________________________________\n",
    "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
    "=================================================================\n",
    "Total params: 20,024,384.0\n",
    "Trainable params: 20,024,384.0\n",
    "Non-trainable params: 0.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers, FUCK WITH THIS\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(dense_final_layer, activation=\"relu\")(x)\n",
    "x = Dropout(final_dropout)(x)\n",
    "x = Dense(dense_final_layer, activation=\"relu\")(x)\n",
    "predictions = Dense(n_labels, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(\n",
    "                        loss      = \"categorical_crossentropy\", \n",
    "                        optimizer = optimizers.SGD(\n",
    "                                                    lr=learning_rate, \n",
    "                                                    momentum=momentum\n",
    "                                                  ), \n",
    "                        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4318 images belonging to 19 classes.\n",
      "Found 1021 images belonging to 19 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "# DIRECTORY IS THE LABEL!!!!!!!!!!!!!!!!!\n",
    "train_datagen = ImageDataGenerator(\n",
    "                                    rescale = 1./255,\n",
    "                                    horizontal_flip = True,\n",
    "                                    fill_mode = \"nearest\",\n",
    "                                    zoom_range = 0.3,\n",
    "                                    width_shift_range = 0.3,\n",
    "                                    height_shift_range=0.3,\n",
    "                                    rotation_range=30,\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                    rescale = 1./255,\n",
    "                                    horizontal_flip = True,\n",
    "                                    fill_mode = \"nearest\",\n",
    "                                    zoom_range = 0.3,\n",
    "                                    width_shift_range = 0.3,\n",
    "                                    height_shift_range=0.3,\n",
    "                                    rotation_range=30\n",
    "                                 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                        train_data_dir,\n",
    "                                                        target_size = (img_height, img_width),\n",
    "                                                        batch_size = batch_size, \n",
    "                                                        class_mode = \"categorical\"\n",
    "                                                   )\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                                                        validation_data_dir,\n",
    "                                                        target_size = (img_height, img_width),\n",
    "                                                        class_mode = \"categorical\"\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\n",
    "                                \"vgg16_1.h5\", \n",
    "                                monitor='val_acc', \n",
    "                                verbose=1, \n",
    "                                save_best_only=True, \n",
    "                                save_weights_only=False, \n",
    "                                mode='auto', \n",
    "                                period=1\n",
    "                            )\n",
    "\n",
    "early = EarlyStopping(\n",
    "                        monitor='val_acc', \n",
    "                        min_delta=0, \n",
    "                        patience=10, \n",
    "                        verbose=1, \n",
    "                        mode='auto'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/sean/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., steps_per_epoch=257, epochs=50, callbacks=[<keras.ca..., validation_steps=466)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  3/257 [..............................] - ETA: 37:11 - loss: 3.0640 - acc: 0.1458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/anaconda/lib/python2.7/site-packages/PIL/Image.py:918: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/257 [>.............................] - ETA: 37:55 - loss: 3.0230 - acc: 0.1364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "                            train_generator,\n",
    "                            samples_per_epoch = nb_train_samples,\n",
    "                            epochs = epochs,\n",
    "                            validation_data = validation_generator,\n",
    "                            nb_val_samples = nb_validation_samples,\n",
    "                            callbacks = [checkpoint, early]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
