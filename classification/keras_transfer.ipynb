{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; got `input_shape=(64, 64, 1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6ee94d17ca60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/sean/anaconda/lib/python2.7/site-packages/keras_applications/vgg19.pyc\u001b[0m in \u001b[0;36mVGG19\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes)\u001b[0m\n\u001b[1;32m    101\u001b[0m                                       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                                       \u001b[0mrequire_flatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                                       weights=weights)\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sean/anaconda/lib/python2.7/site-packages/keras_applications/imagenet_utils.pyc\u001b[0m in \u001b[0;36m_obtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                     raise ValueError('The input must have 3 channels; got '\n\u001b[0;32m--> 310\u001b[0;31m                                      '`input_shape=' + str(input_shape) + '`')\n\u001b[0m\u001b[1;32m    311\u001b[0m                 if ((input_shape[0] is not None and input_shape[0] < min_size) or\n\u001b[1;32m    312\u001b[0m                    (input_shape[1] is not None and input_shape[1] < min_size)):\n",
      "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; got `input_shape=(64, 64, 1)`"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 64, 64\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/val\"\n",
    "nb_train_samples = 4125\n",
    "nb_validation_samples = 466 \n",
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f004d1da350>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d1da5d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d17f3d0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f004d1da610>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d1da6d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d130fd0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f004d14f410>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d13df50>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d0ede90>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d10f5d0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d0fc790>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f004d11ded0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d0bbd10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d0da150>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d06be10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d079f10>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f004d097dd0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d038d10>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004d047e90>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004c5c0ed0>\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f004c5d0b10>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f004c5ed9d0>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLayer (type)                 Output Shape              Param #   \\n=================================================================\\ninput_1 (InputLayer)         (None, 256, 256, 3)       0         \\n_________________________________________________________________\\nblock1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \\n_________________________________________________________________\\nblock1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \\n_________________________________________________________________\\nblock1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \\n_________________________________________________________________\\nblock2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \\n_________________________________________________________________\\nblock2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \\n_________________________________________________________________\\nblock2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \\n_________________________________________________________________\\nblock3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \\n_________________________________________________________________\\nblock3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \\n_________________________________________________________________\\nblock3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \\n_________________________________________________________________\\nblock3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \\n_________________________________________________________________\\nblock3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \\n_________________________________________________________________\\nblock4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \\n_________________________________________________________________\\nblock4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \\n_________________________________________________________________\\nblock4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \\n_________________________________________________________________\\nblock4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \\n_________________________________________________________________\\nblock4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \\n_________________________________________________________________\\nblock5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \\n_________________________________________________________________\\nblock5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \\n_________________________________________________________________\\nblock5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \\n_________________________________________________________________\\nblock5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \\n_________________________________________________________________\\nblock5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \\n=================================================================\\nTotal params: 20,024,384.0\\nTrainable params: 20,024,384.0\\nNon-trainable params: 0.0\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
    "_________________________________________________________________\n",
    "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
    "_________________________________________________________________\n",
    "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
    "_________________________________________________________________\n",
    "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
    "_________________________________________________________________\n",
    "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
    "_________________________________________________________________\n",
    "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
    "_________________________________________________________________\n",
    "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
    "_________________________________________________________________\n",
    "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
    "_________________________________________________________________\n",
    "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_conv4 (Conv2D)        (None, 64, 64, 256)       590080    \n",
    "_________________________________________________________________\n",
    "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
    "_________________________________________________________________\n",
    "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_conv4 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
    "_________________________________________________________________\n",
    "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
    "=================================================================\n",
    "Total params: 20,024,384.0\n",
    "Trainable params: 20,024,384.0\n",
    "Non-trainable params: 0.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers, FUCK WITH THIS\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(16, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "                                    rescale = 1./255,\n",
    "                                    horizontal_flip = True,\n",
    "                                    fill_mode = \"nearest\",\n",
    "                                    zoom_range = 0.3,\n",
    "                                    width_shift_range = 0.3,\n",
    "                                    height_shift_range=0.3,\n",
    "                                    rotation_range=30,\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                    rescale = 1./255,\n",
    "                                    horizontal_flip = True,\n",
    "                                    fill_mode = \"nearest\",\n",
    "                                    zoom_range = 0.3,\n",
    "                                    width_shift_range = 0.3,\n",
    "                                    height_shift_range=0.3,\n",
    "                                    rotation_range=30\n",
    "                                 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                        train_data_dir,\n",
    "                                                        target_size = (img_height, img_width),\n",
    "                                                        batch_size = batch_size, \n",
    "                                                        class_mode = \"categorical\"\n",
    "                                                   )\n",
    "\n",
    "\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "                                                        validation_data_dir,\n",
    "                                                        target_size = (img_height, img_width),\n",
    "                                                        class_mode = \"categorical\"\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\n",
    "                                \"vgg16_1.h5\", \n",
    "                                monitor='val_acc', \n",
    "                                verbose=1, \n",
    "                                save_best_only=True, \n",
    "                                save_weights_only=False, \n",
    "                                mode='auto', \n",
    "                                period=1\n",
    "                            )\n",
    "\n",
    "early = EarlyStopping(\n",
    "                        monitor='val_acc', \n",
    "                        min_delta=0, \n",
    "                        patience=10, \n",
    "                        verbose=1, \n",
    "                        mode='auto'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "                            train_generator,\n",
    "                            samples_per_epoch = nb_train_samples,\n",
    "                            epochs = epochs,\n",
    "                            validation_data = validation_generator,\n",
    "                            nb_val_samples = nb_validation_samples,\n",
    "                            callbacks = [checkpoint, early]\n",
    "                         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
