{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import numpy   as np\n",
    "import pandas  as pd\n",
    "import cPickle as pkl\n",
    "\n",
    "from scipy import stats\n",
    "from PIL   import Image, ImageFilter\n",
    "\n",
    "from sklearn.decomposition   import PCA\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import generate_image_lists as giList\n",
    "import generate_image_labels as giLabels\n",
    "import edge_feature_generation as efg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['figure.figsize'] = (14,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/height_logistic_clf.pkl','r') as f:\n",
    "    _LOGISTIC_HEIGHT_CLF = pkl.load( f )\n",
    "with open('data/short_logistic_clf.pkl','r') as f:\n",
    "    _LOGISTIC_SHORT_CLF  = pkl.load( f )\n",
    "with open('data/long_logistic_clf.pkl','r') as f:\n",
    "    _LOGISTIC_LONG_CLF   = pkl.load( f )\n",
    "with open('data/row_col_pca.pkl'      ,'r') as f:\n",
    "    _RC_PCA              = pkl.load( f )\n",
    "    \n",
    "_SHORT_NUMS = [1,2,4,6,8]\n",
    "_LONG_NUMS  = [1,2,3,4,6,8,10,12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the features from an image\n",
    "def generate_features( img_path ):\n",
    "    \n",
    "    # Returns relative size of axes, and normalized sum of the rows and column\n",
    "    rc_ratio, row_avg, col_avg    = efg.get_img_edge_data( img_path, blur=3 )\n",
    "\n",
    "    # Combine the later\n",
    "    row_col_arr = np.concatenate( ( row_avg, col_avg ) )\n",
    "    \n",
    "    # Run pca to collapse to 1/20 the original size, 85% variance\n",
    "    pca_vals = _RC_PCA.transform( row_col_arr )\n",
    "    \n",
    "    return np.concat( ( np.array(rc_ratio), pca_vals ) )\n",
    "    \n",
    "    \n",
    "# Will generate predictions for provided classes\n",
    "# Can return raw probabilities of being the class,\n",
    "#  or return the expected label\n",
    "def _get_predict( \n",
    "                    inp_arr,\n",
    "                    class_list,\n",
    "                    clf_dict,\n",
    "                    return_prob,\n",
    "                ):\n",
    "    \n",
    "    # Get an idea of how many things we are passing\n",
    "    inp_shape = len( inp_arr.shape )\n",
    "\n",
    "    # If only one element, have to adjust format\n",
    "    if ( inp_shape == 1 ):\n",
    "        pred_arr_format = inp_arr.reshape(1,-1)\n",
    "    else:\n",
    "        pred_arr_format = inp_arr\n",
    "        \n",
    "    # Get the probability of a given class\n",
    "    prob_dict = {}\n",
    "    for classif in class_list:\n",
    "        prob_dict[classif] = clf_dict[classif].predict_proba( pred_arr_format )[:,1]\n",
    "\n",
    "    # If we are just returning the probabilities,\n",
    "    #  can stop here and return a dict\n",
    "    if ( return_prob ):\n",
    "        return prob_dict\n",
    "    \n",
    "    \n",
    "    # Otherwise, go through, find best prediction,\n",
    "    #  and return that\n",
    "    \n",
    "    \n",
    "    out_list = []\n",
    "    \n",
    "    # Compare each prediction, and \n",
    "    #  locate largest values\n",
    "    # Populate the out array with these classes\n",
    "    \n",
    "    # Loop over each element\n",
    "# LATER MODIFY TO CONSIDER THRESHOLD\n",
    "    for i in range( 0, inp_arr.shape[0] ):\n",
    "        \n",
    "        # Loop over classes, finding the best\n",
    "        best_str = class_list[0]\n",
    "        for classif in class_list[1:]:\n",
    "            if ( prob_dict[best_str][i] < prob_dict[classif][i] ):\n",
    "                best_str = classif            \n",
    "        out_list.append( best_str )\n",
    "        \n",
    "    return out_list\n",
    "    \n",
    "# Get predicted height category\n",
    "def get_height_predict( \n",
    "                        inp_arr,\n",
    "                        return_prob=False,\n",
    "                      ):\n",
    "    \n",
    "    # Possible classificatios\n",
    "    class_list = ['height_brick','height_plate','height_other']\n",
    "    clf_dict   = _LOGISTIC_HEIGHT_CLF\n",
    "    \n",
    "    return _get_predict( inp_arr, class_list, clf_dict, return_prob )\n",
    "\n",
    "# Get predicted height category\n",
    "def get_short_predict( \n",
    "                        inp_arr,\n",
    "                        return_prob=False,\n",
    "                      ):\n",
    "    \n",
    "    # Possible classificatios\n",
    "    class_list = ['short_'+str(col) for col in _SHORT_NUMS ]\n",
    "    clf_dict   = _LOGISTIC_SHORT_CLF\n",
    "    \n",
    "    return _get_predict( inp_arr, class_list, clf_dict, return_prob )\n",
    "\n",
    "# Get predicted height category\n",
    "def get_long_predict( \n",
    "                        inp_arr,\n",
    "                        return_prob=False,\n",
    "                      ):\n",
    "    \n",
    "    # Possible classificatios\n",
    "    class_list = ['long_'+str(col) for col in _LONG_NUMS ]\n",
    "    clf_dict   = _LOGISTIC_LONG_CLF\n",
    "    \n",
    "    return _get_predict( inp_arr, class_list, clf_dict, return_prob )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('data/white_labels_edge_pca_50.csv').drop( 'Unnamed: 0',axis=1)\n",
    "\n",
    "feature_cols = ['row_col_ratio'] + [ col for col in full_df.columns.values if ( 'PCA' in col ) ]\n",
    "\n",
    "feature_df = full_df[feature_cols]\n",
    "label_df   = full_df.drop( feature_cols, axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22               plate_2x4\n",
       "23        roof_tile_2x2_45\n",
       "24    roof_tile_1x3_25_inv\n",
       "25    roof_tile_1x3_25_inv\n",
       "26    roof_tile_1x3_25_inv\n",
       "27               plate_4x8\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.loc[i:i+5]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15    plate_2x4\n",
      "16    plate_2x4\n",
      "17    plate_2x4\n",
      "18    plate_2x4\n",
      "19    plate_2x4\n",
      "20    plate_2x4\n",
      "Name: label, dtype: object\n",
      "['height_plate', 'height_plate']\n",
      "['short_2', 'short_2']\n",
      "['long_2', 'long_4']\n"
     ]
    }
   ],
   "source": [
    "i=15\n",
    "print label_df.loc[i:i+5]['label']\n",
    "feat_vals = feature_df.loc[i:i+1].values\n",
    "print get_height_predict( feat_vals )\n",
    "print get_short_predict( feat_vals )\n",
    "print get_long_predict( feat_vals )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
